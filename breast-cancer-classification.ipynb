{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":408,"sourceType":"datasetVersion","datasetId":180}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-04T14:28:55.152185Z","iopub.execute_input":"2025-02-04T14:28:55.152670Z","iopub.status.idle":"2025-02-04T14:28:55.161801Z","shell.execute_reply.started":"2025-02-04T14:28:55.152635Z","shell.execute_reply":"2025-02-04T14:28:55.160308Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/breast-cancer-wisconsin-data/data.csv\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"dataset = pd.read_csv(\"/kaggle/input/breast-cancer-wisconsin-data/data.csv\")\ndel dataset[\"Unnamed: 32\"]\ndel dataset[\"id\"]\ndataset.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T14:28:55.164076Z","iopub.execute_input":"2025-02-04T14:28:55.164513Z","iopub.status.idle":"2025-02-04T14:28:55.195858Z","shell.execute_reply.started":"2025-02-04T14:28:55.164484Z","shell.execute_reply":"2025-02-04T14:28:55.194297Z"}},"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"(569, 31)"},"metadata":{}}],"execution_count":53},{"cell_type":"code","source":"#preparing the data\nx = dataset.drop(columns=[\"diagnosis\"]).values\ny = dataset[\"diagnosis\"].values\n\nencoder=LabelEncoder()\ny= encoder.fit_transform(y)\n\nfrom keras.models import Sequential\nfrom keras.callbacks import EarlyStopping\nfrom keras.layers import Dense, BatchNormalization, Dropout\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle=True, random_state=42)\n\nmodel = Sequential()\nmodel.add(Dense(32, activation=\"relu\", input_shape=(x.shape[1],)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\nmodel.add(Dense(16, activation=\"relu\", ))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1, activation=\"sigmoid\"))\n\nmodel.compile(optimizer=\"adam\",\n             loss=\"binary_crossentropy\",\n             metrics=[\"accuracy\"])\n\ncallback = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\nmodel.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=100, batch_size=16, callbacks=[callback])\n\ntest_loss, test_accuracy = model.evaluate(x_test, y_test)\n\nprint(f\"Test Accuracy: {test_accuracy:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T14:30:01.012530Z","iopub.execute_input":"2025-02-04T14:30:01.013292Z","iopub.status.idle":"2025-02-04T14:30:12.505992Z","shell.execute_reply.started":"2025-02-04T14:30:01.013214Z","shell.execute_reply":"2025-02-04T14:30:12.504769Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8452 - loss: 0.4150 - val_accuracy: 0.3860 - val_loss: 1.1813\nEpoch 2/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8782 - loss: 0.3091 - val_accuracy: 0.5877 - val_loss: 0.6459\nEpoch 3/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8579 - loss: 0.3169 - val_accuracy: 0.7281 - val_loss: 0.4485\nEpoch 4/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8670 - loss: 0.3250 - val_accuracy: 0.8772 - val_loss: 0.3160\nEpoch 5/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8829 - loss: 0.2731 - val_accuracy: 0.9211 - val_loss: 0.2343\nEpoch 6/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8909 - loss: 0.2599 - val_accuracy: 0.9561 - val_loss: 0.1711\nEpoch 7/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9253 - loss: 0.2257 - val_accuracy: 0.9912 - val_loss: 0.1488\nEpoch 8/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8964 - loss: 0.2713 - val_accuracy: 0.9825 - val_loss: 0.1415\nEpoch 9/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9027 - loss: 0.2586 - val_accuracy: 0.9474 - val_loss: 0.1276\nEpoch 10/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8954 - loss: 0.2524 - val_accuracy: 0.9561 - val_loss: 0.1229\nEpoch 11/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9183 - loss: 0.2105 - val_accuracy: 0.9825 - val_loss: 0.1247\nEpoch 12/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9054 - loss: 0.2360 - val_accuracy: 0.9825 - val_loss: 0.1127\nEpoch 13/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8907 - loss: 0.2790 - val_accuracy: 0.9825 - val_loss: 0.1182\nEpoch 14/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8953 - loss: 0.2546 - val_accuracy: 0.9649 - val_loss: 0.1208\nEpoch 15/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9083 - loss: 0.2149 - val_accuracy: 0.9211 - val_loss: 0.1368\nEpoch 16/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9072 - loss: 0.2108 - val_accuracy: 0.9561 - val_loss: 0.1101\nEpoch 17/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8999 - loss: 0.2356 - val_accuracy: 0.9386 - val_loss: 0.1197\nEpoch 18/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9273 - loss: 0.1871 - val_accuracy: 0.9298 - val_loss: 0.1292\nEpoch 19/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9174 - loss: 0.2142 - val_accuracy: 0.9386 - val_loss: 0.1213\nEpoch 20/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9154 - loss: 0.1957 - val_accuracy: 0.9298 - val_loss: 0.1334\nEpoch 21/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9037 - loss: 0.2370 - val_accuracy: 0.9211 - val_loss: 0.1370\nEpoch 22/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9191 - loss: 0.1827 - val_accuracy: 0.9825 - val_loss: 0.1094\nEpoch 23/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9255 - loss: 0.1892 - val_accuracy: 0.9649 - val_loss: 0.1097\nEpoch 24/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9242 - loss: 0.2271 - val_accuracy: 0.9298 - val_loss: 0.1387\nEpoch 25/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9305 - loss: 0.1957 - val_accuracy: 0.9474 - val_loss: 0.1148\nEpoch 26/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9049 - loss: 0.2264 - val_accuracy: 0.9561 - val_loss: 0.1089\nEpoch 27/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8902 - loss: 0.2581 - val_accuracy: 0.9649 - val_loss: 0.1164\nEpoch 28/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9256 - loss: 0.1909 - val_accuracy: 0.9474 - val_loss: 0.1337\nEpoch 29/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9114 - loss: 0.2174 - val_accuracy: 0.9649 - val_loss: 0.1021\nEpoch 30/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9052 - loss: 0.2213 - val_accuracy: 0.9474 - val_loss: 0.1121\nEpoch 31/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8627 - loss: 0.2864 - val_accuracy: 0.9649 - val_loss: 0.0986\nEpoch 32/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9092 - loss: 0.2012 - val_accuracy: 0.9912 - val_loss: 0.0956\nEpoch 33/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9094 - loss: 0.2163 - val_accuracy: 0.9649 - val_loss: 0.1003\nEpoch 34/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9068 - loss: 0.1995 - val_accuracy: 0.9474 - val_loss: 0.1143\nEpoch 35/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9135 - loss: 0.2022 - val_accuracy: 0.9298 - val_loss: 0.1526\nEpoch 36/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9014 - loss: 0.2151 - val_accuracy: 0.9825 - val_loss: 0.0838\nEpoch 37/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8975 - loss: 0.2230 - val_accuracy: 0.9474 - val_loss: 0.1081\nEpoch 38/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9170 - loss: 0.2109 - val_accuracy: 0.9912 - val_loss: 0.0875\nEpoch 39/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9326 - loss: 0.2089 - val_accuracy: 0.9825 - val_loss: 0.0920\nEpoch 40/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8853 - loss: 0.2709 - val_accuracy: 0.9737 - val_loss: 0.0927\nEpoch 41/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9199 - loss: 0.2134 - val_accuracy: 0.9825 - val_loss: 0.1027\nEpoch 42/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9203 - loss: 0.2163 - val_accuracy: 0.9737 - val_loss: 0.1044\nEpoch 43/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8909 - loss: 0.2694 - val_accuracy: 0.9298 - val_loss: 0.1585\nEpoch 44/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9481 - loss: 0.1687 - val_accuracy: 0.9912 - val_loss: 0.0807\nEpoch 45/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9218 - loss: 0.1756 - val_accuracy: 0.9561 - val_loss: 0.0942\nEpoch 46/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9211 - loss: 0.1741 - val_accuracy: 0.9825 - val_loss: 0.0805\nEpoch 47/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9404 - loss: 0.1461 - val_accuracy: 0.9474 - val_loss: 0.1132\nEpoch 48/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9403 - loss: 0.1596 - val_accuracy: 0.9474 - val_loss: 0.1065\nEpoch 49/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9382 - loss: 0.1732 - val_accuracy: 0.9825 - val_loss: 0.0704\nEpoch 50/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9022 - loss: 0.2443 - val_accuracy: 0.9474 - val_loss: 0.1477\nEpoch 51/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9182 - loss: 0.2066 - val_accuracy: 0.9561 - val_loss: 0.0768\nEpoch 52/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9209 - loss: 0.1869 - val_accuracy: 0.9737 - val_loss: 0.0799\nEpoch 53/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8960 - loss: 0.2336 - val_accuracy: 0.9737 - val_loss: 0.0800\nEpoch 54/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9148 - loss: 0.2008 - val_accuracy: 0.9298 - val_loss: 0.1908\nEpoch 55/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9175 - loss: 0.1642 - val_accuracy: 0.9912 - val_loss: 0.0821\nEpoch 56/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9326 - loss: 0.1657 - val_accuracy: 0.9737 - val_loss: 0.0858\nEpoch 57/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9357 - loss: 0.1689 - val_accuracy: 0.9474 - val_loss: 0.1189\nEpoch 58/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9181 - loss: 0.2091 - val_accuracy: 0.9825 - val_loss: 0.0737\nEpoch 59/100\n\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9138 - loss: 0.1911 - val_accuracy: 0.9737 - val_loss: 0.0900\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9857 - loss: 0.0673 \nTest Accuracy: 0.982\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"import numpy as np\nresult = model.predict(x_test)\n# y_pred = (result > 0.5).astype(int)\n\nfor i in range(50):\n    print(f\"Actual label: {y_test[i]} Predicted Label: {y_pred[i][0]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T14:29:09.303084Z","iopub.execute_input":"2025-02-04T14:29:09.303653Z","iopub.status.idle":"2025-02-04T14:29:09.571405Z","shell.execute_reply.started":"2025-02-04T14:29:09.303613Z","shell.execute_reply":"2025-02-04T14:29:09.569536Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\nActual label: 0 Predicted Label: 0\nActual label: 1 Predicted Label: 1\nActual label: 1 Predicted Label: 1\nActual label: 0 Predicted Label: 0\nActual label: 0 Predicted Label: 0\nActual label: 1 Predicted Label: 1\nActual label: 1 Predicted Label: 1\nActual label: 1 Predicted Label: 1\nActual label: 0 Predicted Label: 0\nActual label: 0 Predicted Label: 0\nActual label: 0 Predicted Label: 0\nActual label: 1 Predicted Label: 1\nActual label: 0 Predicted Label: 0\nActual label: 1 Predicted Label: 1\nActual label: 0 Predicted Label: 0\nActual label: 1 Predicted Label: 1\nActual label: 0 Predicted Label: 0\nActual label: 0 Predicted Label: 0\nActual label: 0 Predicted Label: 0\nActual label: 1 Predicted Label: 1\nActual label: 1 Predicted Label: 1\nActual label: 0 Predicted Label: 0\nActual label: 1 Predicted Label: 1\nActual label: 0 Predicted Label: 0\nActual label: 0 Predicted Label: 0\nActual label: 0 Predicted Label: 0\nActual label: 0 Predicted Label: 0\nActual label: 0 Predicted Label: 0\nActual label: 0 Predicted Label: 0\nActual label: 1 Predicted Label: 1\nActual label: 0 Predicted Label: 0\nActual label: 0 Predicted Label: 0\nActual label: 0 Predicted Label: 0\nActual label: 0 Predicted Label: 0\nActual label: 0 Predicted Label: 0\nActual label: 0 Predicted Label: 0\nActual label: 1 Predicted Label: 1\nActual label: 0 Predicted Label: 0\nActual label: 1 Predicted Label: 1\nActual label: 0 Predicted Label: 0\nActual label: 0 Predicted Label: 0\nActual label: 1 Predicted Label: 1\nActual label: 0 Predicted Label: 0\nActual label: 0 Predicted Label: 0\nActual label: 0 Predicted Label: 0\nActual label: 0 Predicted Label: 0\nActual label: 0 Predicted Label: 0\nActual label: 0 Predicted Label: 0\nActual label: 0 Predicted Label: 0\nActual label: 0 Predicted Label: 0\n","output_type":"stream"}],"execution_count":55}]}